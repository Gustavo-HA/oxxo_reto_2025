{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f188cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ruta = r\"C:\\Users\\uzgre\\Codes\\Python\\Datathon\\Reto Oxxo\"\n",
    "archivo = os.path.join(ruta, \"Dataset_Train_limpio2.csv\")\n",
    "\n",
    "# === Lectura del archivo ===\n",
    "with open(archivo, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data = pd.read_csv(f)\n",
    "\n",
    "archivo_test = os.path.join(ruta, \"Dataset_Test_limpio2.csv\")\n",
    "\n",
    "# === Lectura del archivo ===\n",
    "with open(archivo_test, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data_test = pd.read_csv(f)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "x_train = Data.drop(columns=['EXITOSA'])\n",
    "y_train = Data['EXITOSA']\n",
    "\n",
    "x_test = Data_test.drop(columns=['EXITOSA'])\n",
    "y_test = Data_test['EXITOSA']\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "print(Data_test['EXITOSA'].value_counts())\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "modelo = LogisticRegression(penalty='l2', solver='liblinear')  # 'liblinear' para pequeños datasets\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Matriz de Confusión ===\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dda27f",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88304b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uzgre\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:22:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7455    0.7069    0.7257        58\n",
      "         1.0     0.6222    0.6667    0.6437        42\n",
      "\n",
      "    accuracy                         0.6900       100\n",
      "   macro avg     0.6838    0.6868    0.6847       100\n",
      "weighted avg     0.6937    0.6900    0.6912       100\n",
      "\n",
      "\n",
      "=== Matriz de Confusión ===\n",
      "[[41 17]\n",
      " [14 28]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# === Rutas y lectura de datos ===\n",
    "ruta = r\"C:\\Users\\uzgre\\Codes\\Python\\Datathon\\Reto Oxxo\"\n",
    "archivo_train = os.path.join(ruta, \"Dataset_Train_limpio2.csv\")\n",
    "archivo_test = os.path.join(ruta, \"Dataset_Test_limpio2.csv\")\n",
    "\n",
    "# === Carga ===\n",
    "\n",
    "with open(archivo_train, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data = pd.read_csv(f)\n",
    "\n",
    "\n",
    "# === Lectura del archivo ===\n",
    "with open(archivo_test, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data_test = pd.read_csv(f)\n",
    "\n",
    "# === Separación de variables ===\n",
    "X_train = Data.drop(columns=['EXITOSA'])\n",
    "y_train = Data['EXITOSA']\n",
    "\n",
    "X_test = Data_test.drop(columns=['EXITOSA'])\n",
    "y_test = Data_test['EXITOSA']\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Entrenamiento con XGBoost ===\n",
    "modelo = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),  # balanceo de clases\n",
    "    n_estimators=50,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "\n",
    "# === Evaluación ===\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Matriz de Confusión ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Visualización de la matriz de confusión\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ea2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uzgre\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5698 - loss: 0.6875 - val_accuracy: 0.6374 - val_loss: 0.7049\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5681 - loss: 0.6766 - val_accuracy: 0.6044 - val_loss: 0.7070\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5905 - loss: 0.6650 - val_accuracy: 0.6374 - val_loss: 0.7048\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.6657 - val_accuracy: 0.6319 - val_loss: 0.7121\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 0.6802 - val_accuracy: 0.6319 - val_loss: 0.7199\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.6551 - val_accuracy: 0.6319 - val_loss: 0.7245\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.6723 - val_accuracy: 0.6319 - val_loss: 0.7392\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5799 - loss: 0.6671 - val_accuracy: 0.6319 - val_loss: 0.7543\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.6579 - val_accuracy: 0.6319 - val_loss: 0.7560\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.6593 - val_accuracy: 0.6319 - val_loss: 0.7706\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 0.6617 - val_accuracy: 0.6319 - val_loss: 0.7922\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5777 - loss: 0.6568 - val_accuracy: 0.6319 - val_loss: 0.7884\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5943 - loss: 0.6594 - val_accuracy: 0.6319 - val_loss: 0.7934\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 0.6490 - val_accuracy: 0.6319 - val_loss: 0.8309\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: 0.6576 - val_accuracy: 0.6319 - val_loss: 0.8381\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: 0.6589 - val_accuracy: 0.6319 - val_loss: 0.8632\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6319 - loss: 0.6461 - val_accuracy: 0.6319 - val_loss: 0.8924\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.6343 - val_accuracy: 0.6319 - val_loss: 0.8872\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: 0.6430 - val_accuracy: 0.6319 - val_loss: 0.9244\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6256 - loss: 0.6306 - val_accuracy: 0.6319 - val_loss: 0.9373\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5907 - loss: 0.6567 - val_accuracy: 0.6319 - val_loss: 0.9801\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6511 - loss: 0.6339 - val_accuracy: 0.6319 - val_loss: 0.9759\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6589 - loss: 0.6381 - val_accuracy: 0.6319 - val_loss: 0.9919\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6150 - loss: 0.6428 - val_accuracy: 0.6319 - val_loss: 1.0228\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: 0.6294 - val_accuracy: 0.6319 - val_loss: 1.0651\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6239 - loss: 0.6452 - val_accuracy: 0.6319 - val_loss: 1.0632\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6481 - loss: 0.6325 - val_accuracy: 0.6319 - val_loss: 1.0799\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.6444 - val_accuracy: 0.6319 - val_loss: 1.0867\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6401 - loss: 0.6309 - val_accuracy: 0.6319 - val_loss: 1.1572\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6222 - loss: 0.6271 - val_accuracy: 0.6319 - val_loss: 1.1886\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.6421 - val_accuracy: 0.6319 - val_loss: 1.2062\n",
      "Epoch 32/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6493 - loss: 0.6240 - val_accuracy: 0.6319 - val_loss: 1.2018\n",
      "Epoch 33/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 0.6415 - val_accuracy: 0.6319 - val_loss: 1.2830\n",
      "Epoch 34/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 0.6398 - val_accuracy: 0.6209 - val_loss: 1.2971\n",
      "Epoch 35/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6324 - loss: 0.6366 - val_accuracy: 0.6264 - val_loss: 1.3217\n",
      "Epoch 36/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.6400 - val_accuracy: 0.6264 - val_loss: 1.3460\n",
      "Epoch 37/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.6618 - val_accuracy: 0.6264 - val_loss: 1.3426\n",
      "Epoch 38/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.6378 - val_accuracy: 0.6264 - val_loss: 1.3719\n",
      "Epoch 39/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6782 - loss: 0.6115 - val_accuracy: 0.6264 - val_loss: 1.4316\n",
      "Epoch 40/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: 0.6224 - val_accuracy: 0.6264 - val_loss: 1.4640\n",
      "Epoch 41/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.6281 - val_accuracy: 0.6264 - val_loss: 1.5046\n",
      "Epoch 42/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.6290 - val_accuracy: 0.6264 - val_loss: 1.4865\n",
      "Epoch 43/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6465 - loss: 0.6028 - val_accuracy: 0.6209 - val_loss: 1.5587\n",
      "Epoch 44/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: 0.6185 - val_accuracy: 0.6209 - val_loss: 1.5541\n",
      "Epoch 45/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.6074 - val_accuracy: 0.6209 - val_loss: 1.5887\n",
      "Epoch 46/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.6351 - val_accuracy: 0.6209 - val_loss: 1.5614\n",
      "Epoch 47/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.6226 - val_accuracy: 0.6209 - val_loss: 1.5523\n",
      "Epoch 48/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.6312 - val_accuracy: 0.6264 - val_loss: 1.6085\n",
      "Epoch 49/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6860 - loss: 0.6124 - val_accuracy: 0.6209 - val_loss: 1.5712\n",
      "Epoch 50/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6948 - loss: 0.6096 - val_accuracy: 0.6264 - val_loss: 1.6660\n",
      "Epoch 51/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6432 - loss: 0.6248 - val_accuracy: 0.6264 - val_loss: 1.6526\n",
      "Epoch 52/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6691 - loss: 0.6168 - val_accuracy: 0.6264 - val_loss: 1.7301\n",
      "Epoch 53/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6518 - loss: 0.6216 - val_accuracy: 0.6264 - val_loss: 1.7346\n",
      "Epoch 54/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6782 - loss: 0.6168 - val_accuracy: 0.6264 - val_loss: 1.7775\n",
      "Epoch 55/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.6224 - val_accuracy: 0.6209 - val_loss: 1.7428\n",
      "Epoch 56/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6382 - loss: 0.6452 - val_accuracy: 0.6209 - val_loss: 1.7745\n",
      "Epoch 57/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6525 - loss: 0.6124 - val_accuracy: 0.6264 - val_loss: 1.8362\n",
      "Epoch 58/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: 0.6164 - val_accuracy: 0.6209 - val_loss: 1.8370\n",
      "Epoch 59/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6636 - loss: 0.6231 - val_accuracy: 0.6209 - val_loss: 1.8451\n",
      "Epoch 60/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.6050 - val_accuracy: 0.6209 - val_loss: 1.9197\n",
      "Epoch 61/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7022 - loss: 0.5969 - val_accuracy: 0.6209 - val_loss: 1.9820\n",
      "Epoch 62/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6574 - loss: 0.5991 - val_accuracy: 0.6209 - val_loss: 2.0059\n",
      "Epoch 63/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - loss: 0.6224 - val_accuracy: 0.6209 - val_loss: 1.9927\n",
      "Epoch 64/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6431 - loss: 0.6149 - val_accuracy: 0.6209 - val_loss: 2.0926\n",
      "Epoch 65/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 0.6048 - val_accuracy: 0.6209 - val_loss: 2.0008\n",
      "Epoch 66/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.5947 - val_accuracy: 0.6209 - val_loss: 2.0107\n",
      "Epoch 67/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.6125 - val_accuracy: 0.6209 - val_loss: 2.0316\n",
      "Epoch 68/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5849 - val_accuracy: 0.6209 - val_loss: 2.1090\n",
      "Epoch 69/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6604 - loss: 0.6139 - val_accuracy: 0.6209 - val_loss: 2.0895\n",
      "Epoch 70/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.5861 - val_accuracy: 0.6209 - val_loss: 2.0867\n",
      "Epoch 71/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.6178 - val_accuracy: 0.6209 - val_loss: 2.1442\n",
      "Epoch 72/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6678 - loss: 0.6006 - val_accuracy: 0.6209 - val_loss: 2.1917\n",
      "Epoch 73/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6541 - loss: 0.6097 - val_accuracy: 0.6209 - val_loss: 2.2133\n",
      "Epoch 74/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6667 - loss: 0.6079 - val_accuracy: 0.6209 - val_loss: 2.2104\n",
      "Epoch 75/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6607 - loss: 0.5947 - val_accuracy: 0.6209 - val_loss: 2.2873\n",
      "Epoch 76/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6709 - loss: 0.5930 - val_accuracy: 0.6209 - val_loss: 2.3271\n",
      "Epoch 77/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 0.5947 - val_accuracy: 0.6209 - val_loss: 2.3409\n",
      "Epoch 78/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.5980 - val_accuracy: 0.6209 - val_loss: 2.4058\n",
      "Epoch 79/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6660 - loss: 0.5977 - val_accuracy: 0.6209 - val_loss: 2.3695\n",
      "Epoch 80/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.5898 - val_accuracy: 0.6209 - val_loss: 2.4030\n",
      "Epoch 81/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6889 - loss: 0.5862 - val_accuracy: 0.6209 - val_loss: 2.3852\n",
      "Epoch 82/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6959 - loss: 0.6092 - val_accuracy: 0.6209 - val_loss: 2.4668\n",
      "Epoch 83/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 0.5728 - val_accuracy: 0.6209 - val_loss: 2.4239\n",
      "Epoch 84/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7015 - loss: 0.5951 - val_accuracy: 0.6209 - val_loss: 2.4055\n",
      "Epoch 85/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.6081 - val_accuracy: 0.6209 - val_loss: 2.4405\n",
      "Epoch 86/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.6135 - val_accuracy: 0.6209 - val_loss: 2.5000\n",
      "Epoch 87/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.5826 - val_accuracy: 0.6209 - val_loss: 2.4413\n",
      "Epoch 88/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.5991 - val_accuracy: 0.6209 - val_loss: 2.5222\n",
      "Epoch 89/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.5936 - val_accuracy: 0.6209 - val_loss: 2.5233\n",
      "Epoch 90/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 0.5790 - val_accuracy: 0.6209 - val_loss: 2.5645\n",
      "Epoch 91/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.6280 - val_accuracy: 0.6209 - val_loss: 2.5048\n",
      "Epoch 92/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6677 - loss: 0.6131 - val_accuracy: 0.6209 - val_loss: 2.5055\n",
      "Epoch 93/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6618 - loss: 0.5895 - val_accuracy: 0.6209 - val_loss: 2.5647\n",
      "Epoch 94/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.5895 - val_accuracy: 0.6209 - val_loss: 2.6871\n",
      "Epoch 95/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.6078 - val_accuracy: 0.6209 - val_loss: 2.6693\n",
      "Epoch 96/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.5809 - val_accuracy: 0.6209 - val_loss: 2.7114\n",
      "Epoch 97/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.6038 - val_accuracy: 0.6209 - val_loss: 2.6918\n",
      "Epoch 98/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.6049 - val_accuracy: 0.6209 - val_loss: 2.5898\n",
      "Epoch 99/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7096 - loss: 0.5653 - val_accuracy: 0.6209 - val_loss: 2.6497\n",
      "Epoch 100/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6692 - loss: 0.6053 - val_accuracy: 0.6209 - val_loss: 2.6399\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6286    0.7586    0.6875        58\n",
      "         1.0     0.5333    0.3810    0.4444        42\n",
      "\n",
      "    accuracy                         0.6000       100\n",
      "   macro avg     0.5810    0.5698    0.5660       100\n",
      "weighted avg     0.5886    0.6000    0.5854       100\n",
      "\n",
      "\n",
      "=== Matriz de Confusión ===\n",
      "[[44 14]\n",
      " [26 16]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# === Rutas y lectura de datos ===\n",
    "ruta = r\"C:\\Users\\uzgre\\Codes\\Python\\Datathon\\Reto Oxxo\"\n",
    "archivo_train = os.path.join(ruta, \"Dataset_Train_limpio.csv\")\n",
    "archivo_test = os.path.join(ruta, \"Dataset_Test_limpio.csv\")\n",
    "\n",
    "# === Carga ===\n",
    "\n",
    "with open(archivo_train, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data = pd.read_csv(f)\n",
    "\n",
    "\n",
    "# === Lectura del archivo ===\n",
    "with open(archivo_test, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data_test = pd.read_csv(f)\n",
    "\n",
    "cols = [\n",
    "    'LONGITUD_NUM',\n",
    "    'LATITUD_NUM',\n",
    "    'MTS2VENTAS_NUM',\n",
    "    'PUERTASREFRIG_NUM',\n",
    "    'PLAZA_CVE',\n",
    "    'CAJONESESTACIONAMIENTO_NUM',\n",
    "    'NIVELSOCIOECONOMICO_DES',\n",
    "    'EXITOSA'\n",
    "]\n",
    "\n",
    "Data = Data[cols]\n",
    "Data_test = Data_test[cols]\n",
    "\n",
    "# === Separación de variables ===\n",
    "X_train = Data.drop(columns=['EXITOSA'])\n",
    "y_train = Data['EXITOSA']\n",
    "\n",
    "X_test = Data_test.drop(columns=['EXITOSA'])\n",
    "y_test = Data_test['EXITOSA']\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definimos el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # salida binaria\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Entrenamos\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluamos\n",
    "y_pred_probs = model.predict(X_test_scaled).flatten()\n",
    "y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_classes, digits=4))\n",
    "print(\"\\n=== Matriz de Confusión ===\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
